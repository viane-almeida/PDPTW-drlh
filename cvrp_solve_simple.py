#!/usr/bin/env python3
"""
Simple script to solve a single CVRP instance.

This demonstrates the most straightforward way to solve a single CVRP instance.

Usage:
    python cvrp_solve_simple.py
"""

import sys
import os
sys.path.insert(0, '.')

from DRLH.agents import DRL_Agent
from DRLH.problems.cvrp import CVRP


def solve_single_instance():
    """Solve a single CVRP instance step by step."""
    
    print("ğŸš› DRLH CVRP Single Instance Solver")
    print("=" * 40)
    
    # Step 1: Create the problem
    print("\nğŸ“‹ Step 1: Creating CVRP problem...")
    problem = CVRP(
        size=20,                    # 20 customers (manageable size)
        max_steps=500,              # Maximum optimization steps
        T_f=0.05,                   # Final temperature for simulated annealing
        state_rep="reduced_dist___dist_from_min___no_improvement___index_step___was_changed___unseen",
        reward_func="5310",         # Reward function encouraging improvements
        num_cold_start_solves=1     # Generate 1 random instance
    )
    
    print(f"âœ… Problem created: {problem.size} customers, {problem.action_space.n} heuristics available")
    
    # Step 2: Create the agent
    print("\nğŸ¤– Step 2: Creating DRL agent...")
    agent = DRL_Agent(
        problem=problem,
        alpha=0.001,                # Learning rate
        normalization_func="no_normalization",  # Simple for demo
        use_cuda=False              # CPU-only for compatibility
    )
    
    print(f"âœ… Agent created with {problem.observation_space.shape[0]}-dimensional state space")
    
    # Step 3: Try to load a trained model (optional)
    print("\nğŸ“ Step 3: Checking for trained model...")
    model_path = "logs/example_small/models/checkpoint_50.pt"
    if os.path.exists(model_path):
        try:
            print(f"ğŸ”„ Loading trained model: {model_path}")
            agent.load_model(logdir="logs/example_small", i=50)
            print("âœ… Trained model loaded successfully!")
            trained = True
        except Exception as e:
            print(f"âš ï¸  Could not load model: {e}")
            print("ğŸ² Using random policy instead")
            trained = False
    else:
        print("ğŸ² No trained model found, using random policy")
        trained = False
    
    # Step 4: Generate/reset the problem instance
    print("\nğŸ¯ Step 4: Generating problem instance...")
    observation = problem.reset()
    agent.reset(problem.start_distance, problem.max_steps)
    
    print(f"âœ… Instance generated:")
    print(f"   ğŸ“ {problem.size} customers to visit")
    print(f"   ğŸš— Initial solution distance: {problem.start_distance:.4f}")
    print(f"   ğŸ¯ Goal: Minimize total travel distance")
    
    # Step 5: Solve the instance
    print(f"\nğŸ”„ Step 5: Optimizing solution...")
    print("   (Each step selects a heuristic operation to improve the solution)")
    
    done = False
    step = 0
    best_distances = []
    
    while not done and step < 200:  # Limit steps for demo
        # Agent chooses which heuristic to apply
        action, prob, val, dist_ = agent.choose_action(observation)
        
        # Apply the chosen heuristic
        observation_, reward, done, info = problem.step(action)
        
        step += 1
        observation = observation_
        best_distances.append(info["min_distance"])
        
        # Print progress every 25 steps
        if step % 25 == 0:
            improvement = problem.start_distance - info["min_distance"]
            improvement_pct = 100 * improvement / problem.start_distance
            print(f"   Step {step:3d}: Best = {info['min_distance']:.4f}, "
                  f"Improved = {improvement:.4f} ({improvement_pct:.1f}%)")
    
    # Step 6: Show results
    print(f"\nğŸ‰ Step 6: Optimization complete!")
    
    final_distance = info["min_distance"]
    initial_distance = problem.start_distance
    improvement = initial_distance - final_distance
    improvement_pct = 100 * improvement / initial_distance
    
    print(f"\nğŸ“Š RESULTS:")
    print(f"   ğŸ Initial distance:  {initial_distance:.4f}")
    print(f"   ğŸ¯ Final distance:    {final_distance:.4f}")
    print(f"   ğŸ“ˆ Improvement:       {improvement:.4f} ({improvement_pct:.1f}%)")
    print(f"   âš¡ Steps taken:       {step}")
    print(f"   ğŸ§  Model used:        {'Trained' if trained else 'Random'}")
    
    # Show solution quality assessment
    if improvement_pct > 50:
        quality = "ğŸ† Excellent"
    elif improvement_pct > 30:
        quality = "ğŸ¥ˆ Good"
    elif improvement_pct > 10:
        quality = "ğŸ¥‰ Fair"
    else:
        quality = "âŒ Poor"
    
    print(f"   â­ Solution quality:  {quality}")
    
    # Step 7: Show the actual solution
    print(f"\nğŸ—ºï¸  SOLUTION DETAILS:")
    print(f"   ğŸ“ Best route found: {info['best_solution']}")
    print(f"   ğŸ”„ Total improvements made: {info['num_improvements']}")
    print(f"   â° Step where best was found: {info['min_step']}")
    
    # Show most effective heuristics
    print(f"\nğŸ”§ HEURISTIC USAGE:")
    action_counts = info["action_counter"]
    sorted_actions = sorted(action_counts.items(), key=lambda x: x[1], reverse=True)
    
    print("   Most used heuristics:")
    for i, (action_name, count) in enumerate(sorted_actions[:3]):
        if count > 0:
            heuristic_name = action_name.replace("cvrp_", "").replace("_and_", " + ")
            print(f"   {i+1}. {heuristic_name}: {count} times")
    
    return info


def explain_the_process():
    """Explain what the algorithm is doing."""
    print("\n" + "="*60)
    print("ğŸ§  HOW THE DRLH ALGORITHM WORKS")
    print("="*60)
    print()
    print("1. ğŸ¯ PROBLEM: Given customers at different locations with demands,")
    print("   find the shortest routes for vehicles to visit all customers.")
    print()
    print("2. ğŸ§  AGENT: A neural network (PPO) learns to select which")
    print("   optimization heuristic to apply at each step.")
    print()
    print("3. ğŸ”§ HEURISTICS: Classical operations like:")
    print("   â€¢ Remove customers from routes")
    print("   â€¢ Insert customers in better positions")
    print("   â€¢ Swap customers between routes")
    print()
    print("4. ğŸ¯ GOAL: The agent learns which heuristics work best in")
    print("   different situations to minimize total distance.")
    print()
    print("5. ğŸ† RESULT: Intelligent combination of AI learning +")
    print("   classical optimization = better solutions!")


if __name__ == "__main__":
    # Solve an instance
    result = solve_single_instance()
    
    # Explain the process
    explain_the_process()
    
    print(f"\nâœ¨ Ready to solve more instances!")
    print(f"ğŸ’¡ Tip: Run this script multiple times to see different random instances")
